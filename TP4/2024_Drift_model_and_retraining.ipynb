{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LA_QTG8vFs8E"
   },
   "source": [
    "## Modèle en production\n",
    "\n",
    "Laurent Cetinsoy - Datadidacte\n",
    "\n",
    "Une des supposition centrale pour qu'un modèle de machine learning marche est que la distribution des données ne diffère pas de celle des données d'entrainement.\n",
    "\n",
    "On ne peut garantir la généralisation d'un modèle que si la distribution des données est similaire à celle de la distribution $ X_{prod} \\tilde{} \\,  P_{train}$\n",
    "\n",
    "Ainsi, si les données que le modèle voient en production n'ont pas la même distribution (ne ressemblent pas) aux données de train, alors le modèle aura peu de chance de faire de bonne prédictions.\n",
    "\n",
    "Il est donc important de surveille les données vues par le modèle en production.\n",
    "\n",
    "Pour cela on va mesurer ce qu'on appelle le Data drift : on va mesurer à quel point les données s'écartent des données de train.\n",
    "\n",
    "Et on pourra ainsi lever une alerte si c'est le cas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEHFqy-yFs8K"
   },
   "source": [
    "## Utilisation Eurybia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g7Cr8DVyFs8N"
   },
   "source": [
    "\n",
    "En consultant la documentation de Eurybia (https://eurybia.readthedocs.io/en/latest/overview.html), expliquer le principe de fonctionnement de Euribya :\n",
    "\n",
    "- A quoi sert le modèle de classification ?\n",
    "- A-t-on besoin d’avoir les labels issus de la production pour pouvoir utiliser cette approche ?\n",
    "- Quel est le critère pour déterminer qu’il y a un data-drift ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2lpGujbFs8Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAn3sAA7Fs8W"
   },
   "source": [
    "Installer eurybia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUCfIkyzFs8Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6qFJUvoFs8e"
   },
   "source": [
    "Utiliser eurybia pour monitorer le modèle. Dans un premier temps faire en sorte que les données (df_current) soient de la même distribution que vos données d’entraînement. Vérifier que Eurybia pense que le modèle ne drift pas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TjazQyrFs8i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXc0y7gxFs8k"
   },
   "source": [
    "Faire de même avec des données de test. Les données de tests ont-elle un drift par rapport au train ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqxlWgurFs8l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpbUJGhzFs8m"
   },
   "source": [
    "Générer des données qui ne ressemblent ni au train ni au test (par exemple avec des données abérentes). Euribya détecte-t-il ces données ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NYnareE4Fs8o"
   },
   "source": [
    "\n",
    "\n",
    "## Alibaba detect\n",
    "\n",
    "Dans cette partie on va utiliser la librairie https://github.com/SeldonIO/alibi-detect pour faire la détection de problèmes\n",
    "Installer la librairie avec pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WX5iAyTJFs8q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJvFD2xrFs8r"
   },
   "source": [
    "Charger le jeu de donnée cifar10 avec keras et récupérer le train et le test puis,\n",
    "\n",
    "Normaliser les données de train en faisant un MinMaxScaling (diviser par 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X90oWx5AFs8v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45x7yftfFs8w"
   },
   "source": [
    "Dans le sous package alibbi_detect.datasets importer les  fonction fetch_cifar10c et corruption_types_cifar10c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6u6Pp8x9Fs80"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KH81nEs_Fs82"
   },
   "source": [
    "Afficher les types de corruption de données disponible avec la fonction corruption_types_cifar10c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OH0zp3fbFs84"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDTT-67yFs86"
   },
   "source": [
    "Avec la fonction fetch_cifar10c récupérer des exemples corrompus de donnée ressemblant à cifar 10 et les stocker dans des variable X_corrupted et y_corrupted.\n",
    "\n",
    "Vous choisirez 1 ou 2 corruptions parmis les suivantes : ['gaussian_noise', 'motion_blur', 'brightness', 'pixelate']\n",
    "\n",
    "Vous spécifirez les argument severity=5 et return_X_y=True\n",
    "attention le dataset peut être lourd si vous utilisez bcp de corruptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8SL8z_TFs8-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ilj7rn6aFs8_"
   },
   "source": [
    "Normaliser les images corrompues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tS0CR6e5Fs9B"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_mTwk7yFs9B"
   },
   "source": [
    "Afficher plusieurs des images corrompues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHmjeAywFs9C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bev6XyQZFs9D"
   },
   "source": [
    "On va maintenant prendre un modèle entraîné sur cifar10 pour voir l'impact des performances sur le modèle.\n",
    "\n",
    "Avec la fonction  fetch_tf_model du module alibi_detect.utils.fetching, charger le modèle préentraîné resnet32 sur cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOkVyhy2Fs9G"
   },
   "outputs": [],
   "source": [
    "from alibi_detect.utils.fetching import fetch_tf_model, fetch_detector\n",
    "dataset = 'cifar10'\n",
    "model_name = 'resnet32'\n",
    "model = fetch_tf_model(dataset, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSVWdspmFs9K"
   },
   "source": [
    "Calculer la performance du model sur le jeu de train et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IyBxvmGaFs9M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SG82jqxFs9N"
   },
   "source": [
    "Calculer la performance du modèle sur le jeu de donnée corrompu. Vous devriez observer qu'il chute significativement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWux1w8EFs9P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT9bns5tFs9Q"
   },
   "source": [
    "On va maintenant voir comment détecter les changement de distributions de données.\n",
    "\n",
    "Pour les données non tabulaire ou à haute dimension on procéde généralement en deux étapes :\n",
    "\n",
    "1. Faire une réduction de dimension\n",
    "2. Faire un test permettant de voir si les données projetées ont changé de distribution ou pas\n",
    "\n",
    "Il existe plusieurs manières de faire de la réduction de dimension. La plus classique est la PCA.\n",
    "\n",
    "Il est possible également d'utiliser des Auto-encoder\n",
    "\n",
    "Le code suivant permet de créer la première partie (l'encoder) d'un auto-encoder simple qui nous servira à réduire les dimension des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBJao1RXFs9R"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, InputLayer, Reshape\n",
    "from alibi_detect.cd.tensorflow import preprocess_drift\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# define encoder\n",
    "encoding_dim = 32\n",
    "encoder_net = tf.keras.Sequential(\n",
    "  [\n",
    "      InputLayer(input_shape=(32, 32, 3)),\n",
    "      Conv2D(64, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(128, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Conv2D(512, 4, strides=2, padding='same', activation=tf.nn.relu),\n",
    "      Flatten(),\n",
    "      Dense(encoding_dim,)\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mH4ZehyHFs9S"
   },
   "source": [
    "Le drift detector a besoin d'une donnée de référence afin d'effectuer la comparaison avec les données à monitorer.\n",
    "Créer une variable X_ref avec un échantillon aléatoire des données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kk6euJipFs9T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZrtwSr4Fs9Z"
   },
   "source": [
    "A quoi sert le test statistique kolmogorov smirnoff ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XsIOHxBFs9d"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXatEJZOFs9f"
   },
   "source": [
    "Instancier la classe KSDrift dans une variable nommée **detector**\n",
    "\n",
    "Il faut lui passer le dataset de reference, une p value (prendre 0.05) et une fonction permettant de faire le preprocessing. On a créé la fonction pour vous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epmDLfAfFs9i"
   },
   "outputs": [],
   "source": [
    "from alibi_detect.cd.tensorflow import preprocess_drift\n",
    "preprocess_function = partial(preprocess_drift, model=encoder_net, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUSKpqulFs9k"
   },
   "source": [
    "A laide du Drift detector et la méthode predict faire des prediction sur les données de test et sur les données corrompue pour voir si il détecte un changement de distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yfaYUukjFs9o"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
